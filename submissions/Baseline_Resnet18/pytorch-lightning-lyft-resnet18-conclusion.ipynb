{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet18 baseline with simple learning rate finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet18 baseline model with simple Learning rate finder adapted from Sylvian's blog.\n",
    "\n",
    "Reference:\n",
    "\n",
    "1. https://www.kaggle.com/isbhargav/guide-to-pytorch-learning-rate-scheduling\n",
    "2. https://towardsdatascience.com/adaptive-and-cyclical-learning-rates-using-pytorch-2bf904d18dee\n",
    "3. https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html\n",
    "4. https://github.com/davidtvs/pytorch-lr-finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:09.327827Z",
     "iopub.status.busy": "2020-11-14T09:13:09.326926Z",
     "iopub.status.idle": "2020-11-14T09:13:13.237584Z",
     "shell.execute_reply": "2020-11-14T09:13:13.236165Z"
    },
    "papermill": {
     "duration": 3.948053,
     "end_time": "2020-11-14T09:13:13.237728",
     "exception": false,
     "start_time": "2020-11-14T09:13:09.289675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# common imports\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from tempfile import gettempdir\n",
    "\n",
    "# interactive plot libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import init_notebook_mode, iplot # download_plotlyjs, plot\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision.models.resnet import resnet50, resnet18, resnet34, resnet101\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from torch_lr_finder import LRFinder\n",
    "\n",
    "# l5kit imports\n",
    "import l5kit\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:13.290127Z",
     "iopub.status.busy": "2020-11-14T09:13:13.289336Z",
     "iopub.status.idle": "2020-11-14T09:13:14.093767Z",
     "shell.execute_reply": "2020-11-14T09:13:14.092269Z"
    },
    "papermill": {
     "duration": 0.832324,
     "end_time": "2020-11-14T09:13:14.093953",
     "exception": false,
     "start_time": "2020-11-14T09:13:13.261629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!rm -rf /kaggle/working/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.172595Z",
     "iopub.status.busy": "2020-11-14T09:13:14.170150Z",
     "iopub.status.idle": "2020-11-14T09:13:14.178428Z",
     "shell.execute_reply": "2020-11-14T09:13:14.179120Z"
    },
    "papermill": {
     "duration": 0.051339,
     "end_time": "2020-11-14T09:13:14.179295",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.127956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "print(l5kit.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.263220Z",
     "iopub.status.busy": "2020-11-14T09:13:14.262530Z",
     "iopub.status.idle": "2020-11-14T09:13:14.270005Z",
     "shell.execute_reply": "2020-11-14T09:13:14.273176Z"
    },
    "papermill": {
     "duration": 0.05896,
     "end_time": "2020-11-14T09:13:14.273389",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.214429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_no_of_trainable_params(model):\n",
    "    total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    #print(total_trainable_params)\n",
    "    return total_trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.357323Z",
     "iopub.status.busy": "2020-11-14T09:13:14.356420Z",
     "iopub.status.idle": "2020-11-14T09:13:14.440934Z",
     "shell.execute_reply": "2020-11-14T09:13:14.441633Z"
    },
    "papermill": {
     "duration": 0.131663,
     "end_time": "2020-11-14T09:13:14.441846",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.310183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039684,
     "end_time": "2020-11-14T09:13:14.513227",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.473543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.595175Z",
     "iopub.status.busy": "2020-11-14T09:13:14.594272Z",
     "iopub.status.idle": "2020-11-14T09:13:14.601763Z",
     "shell.execute_reply": "2020-11-14T09:13:14.602874Z"
    },
    "papermill": {
     "duration": 0.048864,
     "end_time": "2020-11-14T09:13:14.603092",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.554228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Lyft configs ---\n",
    "cfg = {\n",
    "    'format_version': 4,\n",
    "    'data_path': \"../../lyft-motion-prediction-autonomous-vehicles/\",\n",
    "    'model_params': {\n",
    "        'model_architecture': 'resnet18',\n",
    "        'history_num_frames': 10,\n",
    "        'history_step_size': 1,\n",
    "        'history_delta_time': 0.1,\n",
    "        'future_num_frames': 50,\n",
    "        'future_step_size': 1,\n",
    "        'future_delta_time': 0.1,\n",
    "        'model_name': \"R18_10_330_180_dr_conclusion\",\n",
    "        'lr': 6.3e-6,\n",
    "        'weight_path': \"R18_10_330_180_dr_conclusion_2784k.pth\",\n",
    "        'lr_find' : False, \n",
    "        'train': True, \n",
    "        'validate': False,\n",
    "        'test': False\n",
    "    },\n",
    "\n",
    "    'raster_params': {\n",
    "        'raster_size': [330, 180],\n",
    "        'pixel_size': [0.4, 0.4],\n",
    "        'ego_center': [0.25, 0.5],\n",
    "        'map_type': 'py_semantic',\n",
    "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
    "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
    "        'dataset_meta_key': 'meta.json',\n",
    "        'filter_agents_threshold': 0.5\n",
    "    },\n",
    "\n",
    "    'train_data_loader': {\n",
    "        'key': 'scenes/train.zarr',\n",
    "        'batch_size': 16,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "    \n",
    "    'val_data_loader': {\n",
    "        'key': 'scenes/validate.zarr',\n",
    "        'batch_size': 16,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "\n",
    "    \n",
    "    'test_data_loader': {\n",
    "        'key': 'scenes/test.zarr',\n",
    "        'batch_size': 32,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "\n",
    "    'train_params': {\n",
    "        'train_start_index' : 174001,\n",
    "        'max_num_steps': 11,\n",
    "        'checkpoint_every_n_steps': 5,\n",
    "        'reduction_factor' : 0.9,\n",
    "        'step_size' : 1e5\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.673878Z",
     "iopub.status.busy": "2020-11-14T09:13:14.673067Z",
     "iopub.status.idle": "2020-11-14T09:13:14.677841Z",
     "shell.execute_reply": "2020-11-14T09:13:14.678490Z"
    },
    "papermill": {
     "duration": 0.044685,
     "end_time": "2020-11-14T09:13:14.678652",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.633967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_HISTORY_FRAMES = cfg['model_params']['history_num_frames'] + 1\n",
    "RASTER_IMG_SIZE = cfg['raster_params']['raster_size'][0]\n",
    "NUM_MODES = 3\n",
    "NUMBER_OF_FUTURE_FRAMES = cfg['model_params']['future_num_frames']\n",
    "\n",
    "### TRAIN FROM WHERE LEFT OFF, CHANGE THE STARTING INDICES VARIABLE ACCORDINGLY\n",
    "TRAIN_BATCH_SIZE = cfg['train_data_loader']['batch_size'] \n",
    "TRAIN_START_INDICES = cfg['train_params']['train_start_index']\n",
    "EXTENT_RANGE = 5.0 \n",
    "MIN_FRAMES_FUTURE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.749681Z",
     "iopub.status.busy": "2020-11-14T09:13:14.748721Z",
     "iopub.status.idle": "2020-11-14T09:13:14.751202Z",
     "shell.execute_reply": "2020-11-14T09:13:14.750487Z"
    },
    "papermill": {
     "duration": 0.041572,
     "end_time": "2020-11-14T09:13:14.751327",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.709755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXTENT_RANGE = 5.0 \n",
    "MAX_VELOCITY = 20.0\n",
    "MAX_ACCELERATION = 2.0\n",
    "MAX_YAW_RATE = np.deg2rad(45)\n",
    "dt =cfg['model_params']['history_delta_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0326,
     "end_time": "2020-11-14T09:13:14.816791",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.784191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Rasterize and initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.911391Z",
     "iopub.status.busy": "2020-11-14T09:13:14.909517Z",
     "iopub.status.idle": "2020-11-14T09:13:21.609157Z",
     "shell.execute_reply": "2020-11-14T09:13:21.610686Z"
    },
    "papermill": {
     "duration": 6.753796,
     "end_time": "2020-11-14T09:13:21.610923",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.857127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set env variable for data\n",
    "DIR_INPUT = cfg[\"data_path\"]\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = DIR_INPUT\n",
    "dm = LocalDataManager(None)\n",
    "rasterizer = build_rasterizer(cfg, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026594,
     "end_time": "2020-11-14T09:14:10.767476",
     "exception": false,
     "start_time": "2020-11-14T09:14:10.740882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:14:10.838460Z",
     "iopub.status.busy": "2020-11-14T09:14:10.837212Z",
     "iopub.status.idle": "2020-11-14T09:14:10.847780Z",
     "shell.execute_reply": "2020-11-14T09:14:10.847083Z"
    },
    "papermill": {
     "duration": 0.052976,
     "end_time": "2020-11-14T09:14:10.847893",
     "exception": false,
     "start_time": "2020-11-14T09:14:10.794917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Function utils ---\n",
    "# Original code from https://github.com/lyft/l5kit/blob/20ab033c01610d711c3d36e1963ecec86e8b85b6/l5kit/l5kit/evaluation/metrics.py\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def pytorch_neg_multi_log_likelihood_batch(\n",
    "    gt: Tensor, pred: Tensor, confidences: Tensor, avails: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Compute a negative log-likelihood for the multi-modal scenario.\n",
    "    log-sum-exp trick is used here to avoid underflow and overflow, For more information about it see:\n",
    "    https://en.wikipedia.org/wiki/LogSumExp#log-sum-exp_trick_for_log-domain_calculations\n",
    "    https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/\n",
    "    https://leimao.github.io/blog/LogSumExp/\n",
    "    Args:\n",
    "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        pred (Tensor): array of shape (bs)x(modes)x(time)x(2D coords)\n",
    "        confidences (Tensor): array of shape (bs)x(modes) with a confidence for each mode in each sample\n",
    "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
    "    Returns:\n",
    "        Tensor: negative log-likelihood for this example, a single float number\n",
    "    \"\"\"\n",
    "    assert len(pred.shape) == 4, f\"expected 3D (MxTxC) array for pred, got {pred.shape}\"\n",
    "    batch_size, num_modes, future_len, num_coords = pred.shape\n",
    "\n",
    "    assert gt.shape == (batch_size, future_len, num_coords), f\"expected 2D (Time x Coords) array for gt, got {gt.shape}\"\n",
    "    assert confidences.shape == (batch_size, num_modes), f\"expected 1D (Modes) array for gt, got {confidences.shape}\"\n",
    "    assert torch.allclose(torch.sum(confidences, dim=1), confidences.new_ones((batch_size,))), \"confidences should sum to 1\"\n",
    "    assert avails.shape == (batch_size, future_len), f\"expected 1D (Time) array for gt, got {avails.shape}\"\n",
    "    # assert all data are valid\n",
    "    assert torch.isfinite(pred).all(), \"invalid value found in pred\"\n",
    "    assert torch.isfinite(gt).all(), \"invalid value found in gt\"\n",
    "    assert torch.isfinite(confidences).all(), \"invalid value found in confidences\"\n",
    "    assert torch.isfinite(avails).all(), \"invalid value found in avails\"\n",
    "\n",
    "    # convert to (batch_size, num_modes, future_len, num_coords)\n",
    "    gt = torch.unsqueeze(gt, 1)  # add modes\n",
    "    avails = avails[:, None, :, None]  # add modes and cords\n",
    "\n",
    "    # error (batch_size, num_modes, future_len)\n",
    "    error = torch.sum(((gt - pred) * avails) ** 2, dim=-1)  # reduce coords and use availability\n",
    "\n",
    "    with np.errstate(divide=\"ignore\"):  # when confidence is 0 log goes to -inf, but we're fine with it\n",
    "        # error (batch_size, num_modes)\n",
    "        error = torch.log(confidences) - 0.5 * torch.sum(error, dim=-1)  # reduce time\n",
    "\n",
    "    # use max aggregator on modes for numerical stability\n",
    "    # error (batch_size, num_modes)\n",
    "    max_value, _ = error.max(dim=1, keepdim=True)  # error are negative at this point, so max() gives the minimum one\n",
    "    error = -torch.log(torch.sum(torch.exp(error - max_value), dim=-1, keepdim=True)) - max_value  # reduce modes\n",
    "    # print(\"error\", error)\n",
    "    return torch.mean(error)\n",
    "\n",
    "\n",
    "def pytorch_neg_multi_log_likelihood_single(\n",
    "    gt: Tensor, pred: Tensor, avails: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        pred (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
    "    Returns:\n",
    "        Tensor: negative log-likelihood for this example, a single float number\n",
    "    \"\"\"\n",
    "    # pred (bs)x(time)x(2D coords) --> (bs)x(mode=1)x(time)x(2D coords)\n",
    "    # create confidence (bs)x(mode=1)\n",
    "    batch_size, future_len, num_coords = pred.shape\n",
    "    confidences = pred.new_ones((batch_size, 1))\n",
    "    return pytorch_neg_multi_log_likelihood_batch(gt, pred.unsqueeze(1), confidences, avails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026633,
     "end_time": "2020-11-14T09:14:10.901570",
     "exception": false,
     "start_time": "2020-11-14T09:14:10.874937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:14:10.977683Z",
     "iopub.status.busy": "2020-11-14T09:14:10.976573Z",
     "iopub.status.idle": "2020-11-14T09:14:10.980055Z",
     "shell.execute_reply": "2020-11-14T09:14:10.979492Z"
    },
    "papermill": {
     "duration": 0.051905,
     "end_time": "2020-11-14T09:14:10.980163",
     "exception": false,
     "start_time": "2020-11-14T09:14:10.928258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Lit_MotionPredictor(pl.LightningModule):\n",
    "    def __init__(self, cfg: Dict, criterion, num_modes=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        architecture = cfg[\"model_params\"][\"model_architecture\"]\n",
    "        # This is 512 for resnet18 and resnet34; And it is 2048 for the other resnets\n",
    "        if architecture == \"resnet50\":\n",
    "            backbone_out_features = 2048\n",
    "        else:\n",
    "            backbone_out_features = 512\n",
    "\n",
    "        num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
    "        num_in_channels = 3 + num_history_channels\n",
    "\n",
    "        # X, Y coords for the future positions (output shape: batch_sizex50x2)\n",
    "        self.future_len = cfg[\"model_params\"][\"future_num_frames\"]\n",
    "        num_targets = 2 * cfg[\"model_params\"][\"future_num_frames\"]\n",
    "        self.num_preds = num_targets * num_modes\n",
    "        self.num_modes = num_modes\n",
    "\n",
    "        ##### Layers of the model #####\n",
    "        backbone = eval(architecture)(pretrained=True)\n",
    "        self.backbone = backbone\n",
    "        self.backbone.conv1 = nn.Conv2d(\n",
    "            num_in_channels,\n",
    "            self.backbone.conv1.out_channels,\n",
    "            kernel_size=self.backbone.conv1.kernel_size,\n",
    "            stride=self.backbone.conv1.stride,\n",
    "            padding=self.backbone.conv1.padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(p =0.4)\n",
    "        \n",
    "        # You can add more layers here.\n",
    "        self.fc1 = nn.Linear(in_features=backbone_out_features, out_features=2048)\n",
    "        self.fc2 = nn.Linear(in_features=2048, out_features=512)\n",
    "        self.fc_out = nn.Linear(512, out_features= self.num_preds + self.num_modes)\n",
    "        \n",
    "        # loss function\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "\n",
    "        x = self.backbone.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # fc layers\n",
    "        x = self.dropout(self.fc1(x))\n",
    "        x = self.dropout(self.fc2(x))\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        # pred (batch_size)x(modes)x(time)x(2D coords)\n",
    "        # confidences (batch_size)x(modes)\n",
    "        bs, _ = x.shape\n",
    "        pred, confidences = torch.split(x, self.num_preds, dim=1)\n",
    "        pred = pred.view(bs, self.num_modes, self.future_len, 2)\n",
    "        assert confidences.shape == (bs, self.num_modes)\n",
    "        confidences = torch.softmax(confidences, dim=1)\n",
    "        return pred, confidences\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #print(batch_idx)\n",
    "        inputs = batch[\"image\"]\n",
    "        target_availabilities = batch[\"target_availabilities\"]\n",
    "        targets = batch[\"target_positions\"]\n",
    "        \n",
    "        # Forward pass\n",
    "        preds, confidences = self.forward(inputs)\n",
    "        loss = self.criterion(targets, preds, confidences, target_availabilities)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=cfg[\"model_params\"][\"lr\"])\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lit_MotionPredictor(cfg, pytorch_neg_multi_log_likelihood_batch, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_steps=cfg['train_params']['max_num_steps'],\n",
    "                     auto_lr_find= cfg['model_params']['lr_find'],\n",
    "                    gpus=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:21.670706Z",
     "iopub.status.busy": "2020-11-14T09:13:21.669796Z",
     "iopub.status.idle": "2020-11-14T09:14:09.446071Z",
     "shell.execute_reply": "2020-11-14T09:14:09.445115Z"
    },
    "papermill": {
     "duration": 47.805745,
     "end_time": "2020-11-14T09:14:09.446194",
     "exception": false,
     "start_time": "2020-11-14T09:13:21.640449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train dataset is  17003687\n",
      "==================================TRAIN DATA==================================\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16265    |  4039527   | 320124624  |    38735988   |      112.19     |        248.36        |        79.25         |        24.83         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "Before slicing, start indices are  [11022119 16329088 15471840  3288262  1108361 12263917 11947411 12777139\n",
      " 15959073 15744485]\n",
      "TRAIN_START_INDICES 174001\n",
      "After slicing, start indices are  [16276762 10355343   266891 15334760 12195784 11603488 11599775  9182295\n",
      "   867046 10752636]\n"
     ]
    }
   ],
   "source": [
    "# ===== INIT TRAIN DATASET============================================================\n",
    "if (cfg['model_params']['train'] == True) or (cfg['model_params']['lr_find'] == True):\n",
    "    train_cfg = cfg[\"train_data_loader\"]\n",
    "    train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
    "    train_dataset = AgentDataset(cfg, train_zarr, rasterizer, min_frame_future=MIN_FRAMES_FUTURE)\n",
    "    \n",
    "    print('Length of Train dataset is ' ,len(train_dataset))\n",
    "    print(\"==================================TRAIN DATA==================================\")\n",
    "    print(train_dataset)\n",
    "    \n",
    "    sampled_indices = np.random.choice(len(train_dataset), size = len(train_dataset), replace = False)\n",
    "    print('Before slicing, start indices are ', sampled_indices[0:10])\n",
    "    print('TRAIN_START_INDICES', TRAIN_START_INDICES)\n",
    "    \n",
    "    sampled_indices = sampled_indices[TRAIN_START_INDICES:]\n",
    "    print('After slicing, start indices are ', sampled_indices[0:10])\n",
    "    \n",
    "    Datasampler = SubsetRandomSampler(sampled_indices)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=Datasampler, batch_size=train_cfg[\"batch_size\"], \n",
    "                             num_workers=train_cfg[\"num_workers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16220    |  1622000   | 125423254  |    11733321   |      45.06      |        100.00        |        77.33         |        10.00         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "eval_base_path = cfg['data_path'] + 'scenes/validate_chopped_100'\n",
    "eval_cfg = cfg[\"val_data_loader\"]\n",
    "eval_zarr_path = str(Path(eval_base_path) / Path(dm.require(eval_cfg[\"key\"])).name)\n",
    "eval_mask_path = str(Path(eval_base_path) / \"mask.npz\")\n",
    "eval_gt_path = str(Path(eval_base_path) / \"gt.csv\")\n",
    "\n",
    "eval_zarr = ChunkedDataset(eval_zarr_path).open()\n",
    "eval_mask = np.load(eval_mask_path)[\"arr_0\"]\n",
    "# ===== INIT DATASET AND LOAD MASK\n",
    "eval_dataset = AgentDataset(cfg, eval_zarr, rasterizer, agents_mask=eval_mask)\n",
    "eval_dataloader = DataLoader(eval_dataset, shuffle=eval_cfg[\"shuffle\"], batch_size=eval_cfg[\"batch_size\"], \n",
    "                             num_workers=eval_cfg[\"num_workers\"])\n",
    "print(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type    | Params\n",
      "-------------------------------------\n",
      "0 | backbone | ResNet  | 11 M  \n",
      "1 | dropout  | Dropout | 0     \n",
      "2 | fc1      | Linear  | 1 M   \n",
      "3 | fc2      | Linear  | 1 M   \n",
      "4 | fc_out   | Linear  | 155 K \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55dc970171a24bbb9f448c3fa041435d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader=train_dataloader, val_dataloaders=eval_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR_finder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_finder_results(lr_finder): \n",
    "    # Create subplot grid\n",
    "    fig = make_subplots(rows=1, cols=2)\n",
    "    # layout ={'title': 'Lr_finder_result'}\n",
    "    \n",
    "    # Create a line (trace) for the lr vs loss, gradient of loss\n",
    "    trace0 = go.Scatter(x=lr_finder['log_lr'], y=lr_finder['smooth_loss'],name='log_lr vs smooth_loss')\n",
    "    trace1 = go.Scatter(x=lr_finder['log_lr'], y=lr_finder['grad_loss'],name='log_lr vs loss gradient')\n",
    "\n",
    "    # Add subplot trace & assign to each grid\n",
    "    fig.add_trace(trace0, row=1, col=1)\n",
    "    fig.add_trace(trace1, row=1, col=2)\n",
    "    fig.write_html(cfg['model_params']['weight_path'] + '.html')\n",
    "    iplot(fig, show_link=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lr(data_loader, init_value = 1e-8, final_value=1.0, beta = 0.98, num_batches = 200):\n",
    "    assert(num_batches > 0)\n",
    "    mult = (final_value / init_value) ** (1/num_batches)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    batch_num = 0\n",
    "    avg_loss = 0.0\n",
    "    best_loss = 0.0\n",
    "    smooth_losses = []\n",
    "    raw_losses = []\n",
    "    log_lrs = []\n",
    "    dataloader_it = iter(data_loader)\n",
    "    progress_bar = tqdm(range(num_batches))\n",
    "    \n",
    "    for idx in progress_bar:\n",
    "        batch_num += 1\n",
    "        try:\n",
    "            data = next(dataloader_it)\n",
    "        except StopIteration:\n",
    "            dataloader_it = iter(data_loader)\n",
    "            data = next(dataloader_it)\n",
    "        \n",
    "        # Forward pass\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        \n",
    "        # handle exception in criterion\n",
    "        try:\n",
    "            loss, _, _ = forward(data, model, device)\n",
    "        except:\n",
    "            if len(smooth_losses) > 1:\n",
    "                grad_loss = np.gradient(smooth_losses)\n",
    "            else:\n",
    "                grad_loss = 0.0\n",
    "            lr_finder_results = {'log_lr':log_lrs, 'raw_loss':raw_losses, \n",
    "                                 'smooth_loss':smooth_losses, 'grad_loss': grad_loss}\n",
    "            return lr_finder_results\n",
    "        \n",
    "        #Compute the smoothed loss\n",
    "        avg_loss = beta * avg_loss + (1-beta) *loss.item()\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        \n",
    "        #Stop if the loss is exploding\n",
    "        if batch_num > 5 and smoothed_loss > 8 * best_loss:\n",
    "            if len(smooth_losses) > 1:\n",
    "                grad_loss = np.gradient(smooth_losses)\n",
    "            else:\n",
    "                grad_loss = 0.0\n",
    "            lr_finder_results = {'log_lr':log_lrs, 'raw_loss':raw_losses, \n",
    "                                 'smooth_loss':smooth_losses, 'grad_loss': grad_loss}\n",
    "            return lr_finder_results\n",
    "        \n",
    "        #Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num==1:\n",
    "            best_loss = smoothed_loss\n",
    "        \n",
    "        #Store the values\n",
    "        raw_losses.append(loss.item())\n",
    "        smooth_losses.append(smoothed_loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print info\n",
    "        progress_bar.set_description(f\"loss: {loss.item()},smoothed_loss: {smoothed_loss},lr : {lr}\")\n",
    "\n",
    "        #Update the lr for the next step\n",
    "        lr *= mult\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "    \n",
    "    grad_loss = np.gradient(lr_finder_results['smooth_loss'])\n",
    "    lr_finder_results = {'log_lr':log_lrs, 'raw_loss':raw_losses, \n",
    "                         'smooth_loss':smooth_losses, '': grad_loss}\n",
    "    return lr_finder_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_lr_finder_results(lr_finder_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if cfg['model_params']['lr_find'] == True:\n",
    "    lr_finder_results = find_lr(train_dataloader)\n",
    "    plot_lr_finder_results(lr_finder_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:14:18.840781Z",
     "iopub.status.busy": "2020-11-14T09:14:18.840006Z",
     "iopub.status.idle": "2020-11-14T15:42:09.684525Z",
     "shell.execute_reply": "2020-11-14T15:42:09.611662Z"
    },
    "papermill": {
     "duration": 23270.898973,
     "end_time": "2020-11-14T15:42:09.684755",
     "exception": false,
     "start_time": "2020-11-14T09:14:18.785782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==== TRAINING LOOP =========================================================\n",
    "if cfg[\"model_params\"][\"train\"] == True:\n",
    "    \n",
    "    print('TRAINING ABOUT TO START ... FROM ', TRAIN_START_INDICES, \n",
    "      '  BATCH AND FOR ', cfg['train_params']['max_num_steps'], ' BATCHES', ' WITH BATCH SIZE', TRAIN_BATCH_SIZE)\n",
    "    \n",
    "    tr_it = iter(train_dataloader)\n",
    "    progress_bar = tqdm(range(TRAIN_START_INDICES, \n",
    "                              TRAIN_START_INDICES + cfg[\"train_params\"][\"max_num_steps\"]))\n",
    "    num_iter = cfg[\"train_params\"][\"max_num_steps\"]\n",
    "    losses_train = []\n",
    "    smooth_losses = []\n",
    "    iterations = []\n",
    "    metrics = []\n",
    "    times = []\n",
    "    model_name = cfg[\"model_params\"][\"model_name\"]\n",
    "    start = time.time()\n",
    "    iteration = 0\n",
    "    \n",
    "    for i in progress_bar:\n",
    "        try:\n",
    "            data = next(tr_it)\n",
    "        except StopIteration:\n",
    "            tr_it = iter(train_dataloader)\n",
    "            data = next(tr_it)\n",
    "        \n",
    "        # Forward pass\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        loss, _, _ = forward(data, model, device)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses_train.append(loss.item())\n",
    "\n",
    "        progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {np.mean(losses_train)}\")\n",
    "        if i % cfg['train_params']['checkpoint_every_n_steps'] == 0:\n",
    "            sample_number = i * cfg['train_data_loader']['batch_size']            \n",
    "            state = {\n",
    "              'state_dict': model.state_dict(),\n",
    "              'optimizer': optimizer.state_dict()\n",
    "            }\n",
    "            torch.save(state, f'{model_name}_{sample_number}k.pth')\n",
    "            iterations.append(i)\n",
    "            metrics.append(np.mean(losses_train))\n",
    "            times.append((time.time()-start)/60)\n",
    "        \n",
    "        num_samples = i * cfg['train_data_loader']['batch_size']\n",
    "\n",
    "        #Update the lr for every step size\n",
    "        if((num_samples % cfg['train_params']['step_size'] == 0)and (i > TRAIN_START_INDICES)):\n",
    "            #print('Before lr : ' , optimizer.param_groups[0]['lr'])\n",
    "            optimizer.param_groups[0]['lr'] *= cfg['train_params']['reduction_factor']\n",
    "            #print('After lr : ' , optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    sample_number = i * cfg['train_data_loader']['batch_size']\n",
    "    results = pd.DataFrame({'iterations': iterations, 'metrics (avg)': metrics, 'elapsed_time (mins)': times})\n",
    "    results.to_csv(f\"train_metrics_{model_name}_{sample_number}k.csv\", index = False)\n",
    "    train_losses_csv = pd.DataFrame({'iteration': TRAIN_START_INDICES + np.arange(len(losses_train)), \n",
    "                                 'losses_train': losses_train})\n",
    "    train_losses_csv.to_csv(f\"train_losses_{model_name}_{sample_number}k.csv\", index = False)\n",
    "    print(f\"Total training time is {(time.time()-start)/60} mins\")\n",
    "    print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_validation_score(model, pred_path):\n",
    "    # ==== EVAL LOOP\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    # store information for evaluation\n",
    "    future_coords_offsets_pd = []\n",
    "    timestamps = []\n",
    "    confidences_list = []\n",
    "    agent_ids = []\n",
    "    progress_bar = tqdm(eval_dataloader)\n",
    "\n",
    "    for data in progress_bar:\n",
    "\n",
    "        _, preds, confidences = forward(data, model, device)\n",
    "\n",
    "        #fix for the new environment\n",
    "        preds = preds.cpu().numpy()\n",
    "        world_from_agents = data[\"world_from_agent\"].numpy()\n",
    "        centroids = data[\"centroid\"].numpy()\n",
    "        coords_offset = []\n",
    "\n",
    "        # convert into world coordinates and compute offsets\n",
    "        for idx in range(len(preds)):\n",
    "            for mode in range(3):\n",
    "                preds[idx, mode, :, :] = transform_points(preds[idx, mode, :, :], world_from_agents[idx]) - centroids[idx][:2]\n",
    "\n",
    "        future_coords_offsets_pd.append(preds.copy())\n",
    "        confidences_list.append(confidences.cpu().numpy().copy())\n",
    "        timestamps.append(data[\"timestamp\"].numpy().copy())\n",
    "        agent_ids.append(data[\"track_id\"].numpy().copy())  \n",
    "    \n",
    "    write_pred_csv(pred_path,\n",
    "               timestamps=np.concatenate(timestamps),\n",
    "               track_ids=np.concatenate(agent_ids),\n",
    "               coords=np.concatenate(future_coords_offsets_pd),\n",
    "               confs=np.concatenate(confidences_list),\n",
    "              )\n",
    "    \n",
    "    metrics = compute_metrics_csv(eval_gt_path, pred_path, [neg_multi_log_likelihood, time_displace])\n",
    "    for metric_name, metric_mean in metrics.items():\n",
    "        print(metric_name, metric_mean)\n",
    "    \n",
    "    #return [future_coords_offsets_pd, confidences_list, timestamps, agent_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16220    |  1622000   | 125423254  |    11733321   |      45.06      |        100.00        |        77.33         |        10.00         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "if cfg['model_params']['validate'] == True:\n",
    "    eval_base_path = cfg['data_path'] + 'scenes/validate_chopped_100'\n",
    "    eval_cfg = cfg[\"val_data_loader\"]\n",
    "    eval_zarr_path = str(Path(eval_base_path) / Path(dm.require(eval_cfg[\"key\"])).name)\n",
    "    eval_mask_path = str(Path(eval_base_path) / \"mask.npz\")\n",
    "    eval_gt_path = str(Path(eval_base_path) / \"gt.csv\")\n",
    "\n",
    "    eval_zarr = ChunkedDataset(eval_zarr_path).open()\n",
    "    eval_mask = np.load(eval_mask_path)[\"arr_0\"]\n",
    "    # ===== INIT DATASET AND LOAD MASK\n",
    "    eval_dataset = AgentDataset(cfg, eval_zarr, rasterizer, agents_mask=eval_mask)\n",
    "    eval_dataloader = DataLoader(eval_dataset, shuffle=eval_cfg[\"shuffle\"], batch_size=eval_cfg[\"batch_size\"], \n",
    "                                 num_workers=eval_cfg[\"num_workers\"])\n",
    "    print(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5919/5919 [38:11<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_multi_log_likelihood 51.84549934571347\n",
      "time_displace [0.04976345 0.08536804 0.11834483 0.15023673 0.18067379 0.2105909\n",
      " 0.23958917 0.26813768 0.29628994 0.3244213  0.35065958 0.37636185\n",
      " 0.40208841 0.42675426 0.45015161 0.47352587 0.4958519  0.51831182\n",
      " 0.53876084 0.56009103 0.57952961 0.59907501 0.61771141 0.63686877\n",
      " 0.65594245 0.67467286 0.69180811 0.70923417 0.7262071  0.74357093\n",
      " 0.76115834 0.77805949 0.7952134  0.81144455 0.82906339 0.84802606\n",
      " 0.86576121 0.88474551 0.90226602 0.92096034 0.94039315 0.95919419\n",
      " 0.98020456 1.00284298 1.02640984 1.04959655 1.07349758 1.09756949\n",
      " 1.12593692 1.15363975]\n"
     ]
    }
   ],
   "source": [
    "if cfg['model_params']['validate'] == True:\n",
    "    pred_path = f\"{gettempdir()}/pred.csv\"\n",
    "    model_validation_score(model, pred_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "papermill": {
   "duration": 23353.578731,
   "end_time": "2020-11-14T15:42:18.007035",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-14T09:13:04.428304",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0bf2e1a17494409e8fba1e5d1188d293": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7fbe0c3991b44670924d29e3f575d13f",
        "IPY_MODEL_755fefb7c3f94d6abdd9fceef6d3a19c"
       ],
       "layout": "IPY_MODEL_aaf1b7d88d244e7a9bd13a9bb97e911c"
      }
     },
     "544939fb29904a79bb35c7b0dd81a619": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "62041b37f7e8471cad2d615dbcce59aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "755fefb7c3f94d6abdd9fceef6d3a19c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_62041b37f7e8471cad2d615dbcce59aa",
       "placeholder": "​",
       "style": "IPY_MODEL_544939fb29904a79bb35c7b0dd81a619",
       "value": " 44.7M/44.7M [00:24&lt;00:00, 1.88MB/s]"
      }
     },
     "7fbe0c3991b44670924d29e3f575d13f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cd667c5c9b124707a79155a90726fadf",
       "max": 46827520,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_de6fe70b193d420098037f10d984bf80",
       "value": 46827520
      }
     },
     "aaf1b7d88d244e7a9bd13a9bb97e911c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cd667c5c9b124707a79155a90726fadf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de6fe70b193d420098037f10d984bf80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
