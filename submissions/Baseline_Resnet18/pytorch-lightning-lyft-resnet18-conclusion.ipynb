{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Lightning version of Resnet18 baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:09.327827Z",
     "iopub.status.busy": "2020-11-14T09:13:09.326926Z",
     "iopub.status.idle": "2020-11-14T09:13:13.237584Z",
     "shell.execute_reply": "2020-11-14T09:13:13.236165Z"
    },
    "papermill": {
     "duration": 3.948053,
     "end_time": "2020-11-14T09:13:13.237728",
     "exception": false,
     "start_time": "2020-11-14T09:13:09.289675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# common imports\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from tempfile import gettempdir\n",
    "\n",
    "# interactive plot libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import init_notebook_mode, iplot # download_plotlyjs, plot\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision.models.resnet import resnet50, resnet18, resnet34, resnet101\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from torch_lr_finder import LRFinder\n",
    "\n",
    "# l5kit imports\n",
    "import l5kit\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.172595Z",
     "iopub.status.busy": "2020-11-14T09:13:14.170150Z",
     "iopub.status.idle": "2020-11-14T09:13:14.178428Z",
     "shell.execute_reply": "2020-11-14T09:13:14.179120Z"
    },
    "papermill": {
     "duration": 0.051339,
     "end_time": "2020-11-14T09:13:14.179295",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.127956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "print(l5kit.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.263220Z",
     "iopub.status.busy": "2020-11-14T09:13:14.262530Z",
     "iopub.status.idle": "2020-11-14T09:13:14.270005Z",
     "shell.execute_reply": "2020-11-14T09:13:14.273176Z"
    },
    "papermill": {
     "duration": 0.05896,
     "end_time": "2020-11-14T09:13:14.273389",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.214429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_no_of_trainable_params(model):\n",
    "    total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    #print(total_trainable_params)\n",
    "    return total_trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.357323Z",
     "iopub.status.busy": "2020-11-14T09:13:14.356420Z",
     "iopub.status.idle": "2020-11-14T09:13:14.440934Z",
     "shell.execute_reply": "2020-11-14T09:13:14.441633Z"
    },
    "papermill": {
     "duration": 0.131663,
     "end_time": "2020-11-14T09:13:14.441846",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.310183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039684,
     "end_time": "2020-11-14T09:13:14.513227",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.473543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.595175Z",
     "iopub.status.busy": "2020-11-14T09:13:14.594272Z",
     "iopub.status.idle": "2020-11-14T09:13:14.601763Z",
     "shell.execute_reply": "2020-11-14T09:13:14.602874Z"
    },
    "papermill": {
     "duration": 0.048864,
     "end_time": "2020-11-14T09:13:14.603092",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.554228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Lyft configs ---\n",
    "cfg = {\n",
    "    'format_version': 4,\n",
    "    'data_path': \"../../lyft-motion-prediction-autonomous-vehicles/\",\n",
    "    'model_params': {\n",
    "        'model_architecture': 'resnet18',\n",
    "        'history_num_frames': 10,\n",
    "        'history_step_size': 1,\n",
    "        'history_delta_time': 0.1,\n",
    "        'future_num_frames': 50,\n",
    "        'future_step_size': 1,\n",
    "        'future_delta_time': 0.1,\n",
    "        'model_name': \"R18_10_330_180_dr_Lit\",\n",
    "        'lr': 1.3e-3,\n",
    "        'weight_path': \"\",\n",
    "        'lr_find' : False, \n",
    "        'train': True, \n",
    "        'validate': False,\n",
    "        'test': False\n",
    "    },\n",
    "\n",
    "    'raster_params': {\n",
    "        'raster_size': [330, 180],\n",
    "        'pixel_size': [0.4, 0.4],\n",
    "        'ego_center': [0.25, 0.5],\n",
    "        'map_type': 'py_semantic',\n",
    "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
    "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
    "        'dataset_meta_key': 'meta.json',\n",
    "        'filter_agents_threshold': 0.5\n",
    "    },\n",
    "\n",
    "    'train_data_loader': {\n",
    "        'key': 'scenes/train.zarr',\n",
    "        'batch_size': 16,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "    \n",
    "    'val_data_loader': {\n",
    "        'key': 'scenes/validate.zarr',\n",
    "        'batch_size': 16,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "\n",
    "    \n",
    "    'test_data_loader': {\n",
    "        'key': 'scenes/test.zarr',\n",
    "        'batch_size': 32,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "\n",
    "    'train_params': {\n",
    "        'train_start_batch_index' : 0,\n",
    "        'max_num_steps': 11,\n",
    "        'checkpoint_every_n_steps': 5,\n",
    "        'reduction_factor' : 0.9,\n",
    "        'step_size' : 1e5\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.673878Z",
     "iopub.status.busy": "2020-11-14T09:13:14.673067Z",
     "iopub.status.idle": "2020-11-14T09:13:14.677841Z",
     "shell.execute_reply": "2020-11-14T09:13:14.678490Z"
    },
    "papermill": {
     "duration": 0.044685,
     "end_time": "2020-11-14T09:13:14.678652",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.633967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_HISTORY_FRAMES = cfg['model_params']['history_num_frames'] + 1\n",
    "RASTER_IMG_SIZE = cfg['raster_params']['raster_size'][0]\n",
    "NUM_MODES = 3\n",
    "NUMBER_OF_FUTURE_FRAMES = cfg['model_params']['future_num_frames']\n",
    "\n",
    "### TRAIN FROM WHERE LEFT OFF, CHANGE THE STARTING INDICES VARIABLE ACCORDINGLY\n",
    "TRAIN_BATCH_SIZE = cfg['train_data_loader']['batch_size'] \n",
    "TRAIN_START_BATCH_INDICES = cfg['train_params']['train_start_batch_index']\n",
    "EXTENT_RANGE = 5.0 \n",
    "MIN_FRAMES_FUTURE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.749681Z",
     "iopub.status.busy": "2020-11-14T09:13:14.748721Z",
     "iopub.status.idle": "2020-11-14T09:13:14.751202Z",
     "shell.execute_reply": "2020-11-14T09:13:14.750487Z"
    },
    "papermill": {
     "duration": 0.041572,
     "end_time": "2020-11-14T09:13:14.751327",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.709755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXTENT_RANGE = 5.0 \n",
    "MAX_VELOCITY = 20.0\n",
    "MAX_ACCELERATION = 2.0\n",
    "MAX_YAW_RATE = np.deg2rad(45)\n",
    "dt =cfg['model_params']['history_delta_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0326,
     "end_time": "2020-11-14T09:13:14.816791",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.784191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Rasterize and initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.911391Z",
     "iopub.status.busy": "2020-11-14T09:13:14.909517Z",
     "iopub.status.idle": "2020-11-14T09:13:21.609157Z",
     "shell.execute_reply": "2020-11-14T09:13:21.610686Z"
    },
    "papermill": {
     "duration": 6.753796,
     "end_time": "2020-11-14T09:13:21.610923",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.857127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set env variable for data\n",
    "DIR_INPUT = cfg[\"data_path\"]\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = DIR_INPUT\n",
    "dm = LocalDataManager(None)\n",
    "rasterizer = build_rasterizer(cfg, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026594,
     "end_time": "2020-11-14T09:14:10.767476",
     "exception": false,
     "start_time": "2020-11-14T09:14:10.740882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:14:10.838460Z",
     "iopub.status.busy": "2020-11-14T09:14:10.837212Z",
     "iopub.status.idle": "2020-11-14T09:14:10.847780Z",
     "shell.execute_reply": "2020-11-14T09:14:10.847083Z"
    },
    "papermill": {
     "duration": 0.052976,
     "end_time": "2020-11-14T09:14:10.847893",
     "exception": false,
     "start_time": "2020-11-14T09:14:10.794917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Function utils ---\n",
    "# Original code from https://github.com/lyft/l5kit/blob/20ab033c01610d711c3d36e1963ecec86e8b85b6/l5kit/l5kit/evaluation/metrics.py\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def pytorch_neg_multi_log_likelihood_batch(\n",
    "    gt: Tensor, pred: Tensor, confidences: Tensor, avails: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Compute a negative log-likelihood for the multi-modal scenario.\n",
    "    log-sum-exp trick is used here to avoid underflow and overflow, For more information about it see:\n",
    "    https://en.wikipedia.org/wiki/LogSumExp#log-sum-exp_trick_for_log-domain_calculations\n",
    "    https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/\n",
    "    https://leimao.github.io/blog/LogSumExp/\n",
    "    Args:\n",
    "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        pred (Tensor): array of shape (bs)x(modes)x(time)x(2D coords)\n",
    "        confidences (Tensor): array of shape (bs)x(modes) with a confidence for each mode in each sample\n",
    "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
    "    Returns:\n",
    "        Tensor: negative log-likelihood for this example, a single float number\n",
    "    \"\"\"\n",
    "    assert len(pred.shape) == 4, f\"expected 3D (MxTxC) array for pred, got {pred.shape}\"\n",
    "    batch_size, num_modes, future_len, num_coords = pred.shape\n",
    "\n",
    "    assert gt.shape == (batch_size, future_len, num_coords), f\"expected 2D (Time x Coords) array for gt, got {gt.shape}\"\n",
    "    assert confidences.shape == (batch_size, num_modes), f\"expected 1D (Modes) array for gt, got {confidences.shape}\"\n",
    "    assert torch.allclose(torch.sum(confidences, dim=1), confidences.new_ones((batch_size,))), \"confidences should sum to 1\"\n",
    "    assert avails.shape == (batch_size, future_len), f\"expected 1D (Time) array for gt, got {avails.shape}\"\n",
    "    # assert all data are valid\n",
    "    assert torch.isfinite(pred).all(), \"invalid value found in pred\"\n",
    "    assert torch.isfinite(gt).all(), \"invalid value found in gt\"\n",
    "    assert torch.isfinite(confidences).all(), \"invalid value found in confidences\"\n",
    "    assert torch.isfinite(avails).all(), \"invalid value found in avails\"\n",
    "\n",
    "    # convert to (batch_size, num_modes, future_len, num_coords)\n",
    "    gt = torch.unsqueeze(gt, 1)  # add modes\n",
    "    avails = avails[:, None, :, None]  # add modes and cords\n",
    "\n",
    "    # error (batch_size, num_modes, future_len)\n",
    "    error = torch.sum(((gt - pred) * avails) ** 2, dim=-1)  # reduce coords and use availability\n",
    "\n",
    "    with np.errstate(divide=\"ignore\"):  # when confidence is 0 log goes to -inf, but we're fine with it\n",
    "        # error (batch_size, num_modes)\n",
    "        error = torch.log(confidences) - 0.5 * torch.sum(error, dim=-1)  # reduce time\n",
    "\n",
    "    # use max aggregator on modes for numerical stability\n",
    "    # error (batch_size, num_modes)\n",
    "    max_value, _ = error.max(dim=1, keepdim=True)  # error are negative at this point, so max() gives the minimum one\n",
    "    error = -torch.log(torch.sum(torch.exp(error - max_value), dim=-1, keepdim=True)) - max_value  # reduce modes\n",
    "    # print(\"error\", error)\n",
    "    return torch.mean(error)\n",
    "\n",
    "\n",
    "def pytorch_neg_multi_log_likelihood_single(\n",
    "    gt: Tensor, pred: Tensor, avails: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        pred (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
    "    Returns:\n",
    "        Tensor: negative log-likelihood for this example, a single float number\n",
    "    \"\"\"\n",
    "    # pred (bs)x(time)x(2D coords) --> (bs)x(mode=1)x(time)x(2D coords)\n",
    "    # create confidence (bs)x(mode=1)\n",
    "    batch_size, future_len, num_coords = pred.shape\n",
    "    confidences = pred.new_ones((batch_size, 1))\n",
    "    return pytorch_neg_multi_log_likelihood_batch(gt, pred.unsqueeze(1), confidences, avails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026633,
     "end_time": "2020-11-14T09:14:10.901570",
     "exception": false,
     "start_time": "2020-11-14T09:14:10.874937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Lit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:14:10.977683Z",
     "iopub.status.busy": "2020-11-14T09:14:10.976573Z",
     "iopub.status.idle": "2020-11-14T09:14:10.980055Z",
     "shell.execute_reply": "2020-11-14T09:14:10.979492Z"
    },
    "papermill": {
     "duration": 0.051905,
     "end_time": "2020-11-14T09:14:10.980163",
     "exception": false,
     "start_time": "2020-11-14T09:14:10.928258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Lit_MotionPredictor(pl.LightningModule):\n",
    "    def __init__(self, cfg: Dict, criterion, num_modes=3, lr=cfg['model_params']['lr']):\n",
    "        super().__init__()\n",
    "        \n",
    "        architecture = cfg[\"model_params\"][\"model_architecture\"]\n",
    "        # This is 512 for resnet18 and resnet34; And it is 2048 for the other resnets\n",
    "        if architecture == \"resnet50\":\n",
    "            backbone_out_features = 2048\n",
    "        else:\n",
    "            backbone_out_features = 512\n",
    "\n",
    "        num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
    "        num_in_channels = 3 + num_history_channels\n",
    "\n",
    "        # X, Y coords for the future positions (output shape: batch_sizex50x2)\n",
    "        self.future_len = cfg[\"model_params\"][\"future_num_frames\"]\n",
    "        num_targets = 2 * cfg[\"model_params\"][\"future_num_frames\"]\n",
    "        self.num_preds = num_targets * num_modes\n",
    "        self.num_modes = num_modes\n",
    "\n",
    "        ##### Layers of the model #####\n",
    "        backbone = eval(architecture)(pretrained=True)\n",
    "        self.backbone = backbone\n",
    "        self.backbone.conv1 = nn.Conv2d(\n",
    "            num_in_channels,\n",
    "            self.backbone.conv1.out_channels,\n",
    "            kernel_size=self.backbone.conv1.kernel_size,\n",
    "            stride=self.backbone.conv1.stride,\n",
    "            padding=self.backbone.conv1.padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(p =0.4)\n",
    "        \n",
    "        # You can add more layers here.\n",
    "        self.fc1 = nn.Linear(in_features=backbone_out_features, out_features=2048)\n",
    "        self.fc2 = nn.Linear(in_features=2048, out_features=512)\n",
    "        self.fc_out = nn.Linear(512, out_features= self.num_preds + self.num_modes)\n",
    "        \n",
    "        # loss function\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        # learning_rate assign\n",
    "        self.learning_rate = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "\n",
    "        x = self.backbone.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # fc layers\n",
    "        x = self.dropout(self.fc1(x))\n",
    "        x = self.dropout(self.fc2(x))\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        # pred (batch_size)x(modes)x(time)x(2D coords)\n",
    "        # confidences (batch_size)x(modes)\n",
    "        bs, _ = x.shape\n",
    "        pred, confidences = torch.split(x, self.num_preds, dim=1)\n",
    "        pred = pred.view(bs, self.num_modes, self.future_len, 2)\n",
    "        assert confidences.shape == (bs, self.num_modes)\n",
    "        confidences = torch.softmax(confidences, dim=1)\n",
    "        return pred, confidences\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #print(batch_idx)\n",
    "        inputs = batch[\"image\"]\n",
    "        target_availabilities = batch[\"target_availabilities\"]\n",
    "        targets = batch[\"target_positions\"]\n",
    "        \n",
    "        # Forward pass\n",
    "        preds, confidences = self.forward(inputs)\n",
    "        loss = self.criterion(targets, preds, confidences, target_availabilities)\n",
    "        \n",
    "        if((batch_idx!=0) and (batch_idx % cfg['train_params']['checkpoint_every_n_steps'] == 0)):\n",
    "            sample_number = batch_idx * cfg['train_data_loader']['batch_size']            \n",
    "            trainer.save_checkpoint(cfg['model_params']['model_name'] + str(sample_number) + '.ckpt')\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=self.learning_rate,\n",
    "                                                  total_steps=cfg['train_params']['max_num_steps'],\n",
    "                                                  pct_start=0.4, div_factor=10)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lit_MotionPredictor(cfg, pytorch_neg_multi_log_likelihood_batch, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:21.670706Z",
     "iopub.status.busy": "2020-11-14T09:13:21.669796Z",
     "iopub.status.idle": "2020-11-14T09:14:09.446071Z",
     "shell.execute_reply": "2020-11-14T09:14:09.445115Z"
    },
    "papermill": {
     "duration": 47.805745,
     "end_time": "2020-11-14T09:14:09.446194",
     "exception": false,
     "start_time": "2020-11-14T09:13:21.640449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train dataset is  17003687\n",
      "==================================TRAIN DATA==================================\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16265    |  4039527   | 320124624  |    38735988   |      112.19     |        248.36        |        79.25         |        24.83         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "Before slicing, start indices are  [11022119 16329088 15471840  3288262  1108361]\n",
      "TRAIN_START_INDICES 0\n",
      "After slicing, start indices are  [11022119 16329088 15471840  3288262  1108361]\n"
     ]
    }
   ],
   "source": [
    "# ===== INIT TRAIN DATASET============================================================\n",
    "if (cfg['model_params']['train'] == True) or (cfg['model_params']['lr_find'] == True):\n",
    "    train_cfg = cfg[\"train_data_loader\"]\n",
    "    train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
    "    train_dataset = AgentDataset(cfg, train_zarr, rasterizer, min_frame_future=MIN_FRAMES_FUTURE)\n",
    "    \n",
    "    print('Length of Train dataset is ' ,len(train_dataset))\n",
    "    print(\"==================================TRAIN DATA==================================\")\n",
    "    print(train_dataset)\n",
    "    \n",
    "    sampled_indices = np.random.choice(len(train_dataset), size = len(train_dataset), replace = False)\n",
    "    print('Before slicing, start indices are ', sampled_indices[0:5])\n",
    "    print('TRAIN_START_INDICES', TRAIN_START_BATCH_INDICES * TRAIN_BATCH_SIZE)\n",
    "    \n",
    "    sampled_indices = sampled_indices[TRAIN_START_BATCH_INDICES * TRAIN_BATCH_SIZE:]\n",
    "    print('After slicing, start indices are ', sampled_indices[0:5])\n",
    "    \n",
    "    Datasampler = SubsetRandomSampler(sampled_indices)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=Datasampler, batch_size=train_cfg[\"batch_size\"], \n",
    "                             num_workers=train_cfg[\"num_workers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset) 17003687\n",
      "len(sampled_indices) 17003687\n",
      "len(train_dataloader) 1062731\n"
     ]
    }
   ],
   "source": [
    "print('len(train_dataset)', len(train_dataset))\n",
    "print('len(sampled_indices)', len(sampled_indices))\n",
    "print('len(train_dataloader)', len(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16220    |  1622000   | 125423254  |    11733321   |      45.06      |        100.00        |        77.33         |        10.00         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "eval_base_path = cfg['data_path'] + 'scenes/validate_chopped_100'\n",
    "eval_cfg = cfg[\"val_data_loader\"]\n",
    "eval_zarr_path = str(Path(eval_base_path) / Path(dm.require(eval_cfg[\"key\"])).name)\n",
    "eval_mask_path = str(Path(eval_base_path) / \"mask.npz\")\n",
    "eval_gt_path = str(Path(eval_base_path) / \"gt.csv\")\n",
    "\n",
    "eval_zarr = ChunkedDataset(eval_zarr_path).open()\n",
    "eval_mask = np.load(eval_mask_path)[\"arr_0\"]\n",
    "# ===== INIT DATASET AND LOAD MASK\n",
    "eval_dataset = AgentDataset(cfg, eval_zarr, rasterizer, agents_mask=eval_mask)\n",
    "eval_dataloader = DataLoader(eval_dataset, shuffle=eval_cfg[\"shuffle\"], batch_size=eval_cfg[\"batch_size\"], \n",
    "                             num_workers=eval_cfg[\"num_workers\"])\n",
    "print(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lit Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath=cfg['model_params']['model_name'] + '.ckpt',\n",
    "    save_best_only=True,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, max_steps=cfg['train_params']['max_num_steps'],\n",
    "                    limit_val_batches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Finder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg['model_params']['lr_find'] == True:\n",
    "    # Run learning rate finder\n",
    "    lr_finder = trainer.tuner.lr_find(model,train_dataloader=train_dataloader, \n",
    "                                       max_lr=7.5e-3, early_stop_threshold=3.0)\n",
    "    \n",
    "    # Plot the results\n",
    "    fig = lr_finder.plot(suggest=True)\n",
    "    fig.show()\n",
    "    \n",
    "    # set the learning rate of the model as per suggestion\n",
    "    print('Before lr : ', model.learning_rate)\n",
    "    model.learning_rate = lr_finder.suggestion()\n",
    "    print('AFTER lr : ', model.learning_rate)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lit Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type    | Params\n",
      "-------------------------------------\n",
      "0 | backbone | ResNet  | 11 M  \n",
      "1 | dropout  | Dropout | 0     \n",
      "2 | fc1      | Linear  | 1 M   \n",
      "3 | fc2      | Linear  | 1 M   \n",
      "4 | fc_out   | Linear  | 155 K \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1646141abdfa46b1a21260c574ea94e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if cfg['model_params']['train'] == True:\n",
    "    trainer.fit(model, train_dataloader=train_dataloader, val_dataloaders=eval_dataloader)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class LyftMultiModel(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg: Dict, num_modes=3):\n",
    "        super().__init__()\n",
    "\n",
    "        architecture = cfg[\"model_params\"][\"model_architecture\"]\n",
    "        backbone = eval(architecture)(pretrained=True)\n",
    "        self.backbone = backbone\n",
    "\n",
    "        num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
    "        num_in_channels = 3 + num_history_channels\n",
    "\n",
    "        self.backbone.conv1 = nn.Conv2d(\n",
    "            num_in_channels,\n",
    "            self.backbone.conv1.out_channels,\n",
    "            kernel_size=self.backbone.conv1.kernel_size,\n",
    "            stride=self.backbone.conv1.stride,\n",
    "            padding=self.backbone.conv1.padding,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        # This is 512 for resnet18 and resnet34;\n",
    "        # And it is 2048 for the other resnets\n",
    "        \n",
    "        if architecture == \"resnet50\":\n",
    "            backbone_out_features = 2048\n",
    "        else:\n",
    "            backbone_out_features = 512\n",
    "\n",
    "        # X, Y coords for the future positions (output shape: batch_sizex50x2)\n",
    "        self.future_len = cfg[\"model_params\"][\"future_num_frames\"]\n",
    "        num_targets = 2 * self.future_len\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(p =0.4)\n",
    "        \n",
    "        # You can add more layers here.\n",
    "        self.fc1 = nn.Linear(in_features=backbone_out_features, out_features=2048)\n",
    "        self.fc2 = nn.Linear(in_features=2048, out_features=512)\n",
    "\n",
    "        self.num_preds = num_targets * num_modes\n",
    "        self.num_modes = num_modes\n",
    "\n",
    "        self.fc_out = nn.Linear(512, out_features=self.num_preds + num_modes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "\n",
    "        x = self.backbone.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # fc layers\n",
    "        x = self.dropout(self.fc1(x))\n",
    "        x = self.dropout(self.fc2(x))\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        # pred (batch_size)x(modes)x(time)x(2D coords)\n",
    "        # confidences (batch_size)x(modes)\n",
    "        bs, _ = x.shape\n",
    "        pred, confidences = torch.split(x, self.num_preds, dim=1)\n",
    "        pred = pred.view(bs, self.num_modes, self.future_len, 2)\n",
    "        assert confidences.shape == (bs, self.num_modes)\n",
    "        confidences = torch.softmax(confidences, dim=1)\n",
    "        return pred, confidences"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pytorch_model = LyftMultiModel(cfg)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "checkpoint = torch.load('R18_10_330_180_dr_conclusion_880k.pth')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trainer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR_finder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "papermill": {
   "duration": 23353.578731,
   "end_time": "2020-11-14T15:42:18.007035",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-14T09:13:04.428304",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0bf2e1a17494409e8fba1e5d1188d293": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7fbe0c3991b44670924d29e3f575d13f",
        "IPY_MODEL_755fefb7c3f94d6abdd9fceef6d3a19c"
       ],
       "layout": "IPY_MODEL_aaf1b7d88d244e7a9bd13a9bb97e911c"
      }
     },
     "544939fb29904a79bb35c7b0dd81a619": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "62041b37f7e8471cad2d615dbcce59aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "755fefb7c3f94d6abdd9fceef6d3a19c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_62041b37f7e8471cad2d615dbcce59aa",
       "placeholder": "​",
       "style": "IPY_MODEL_544939fb29904a79bb35c7b0dd81a619",
       "value": " 44.7M/44.7M [00:24&lt;00:00, 1.88MB/s]"
      }
     },
     "7fbe0c3991b44670924d29e3f575d13f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cd667c5c9b124707a79155a90726fadf",
       "max": 46827520,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_de6fe70b193d420098037f10d984bf80",
       "value": 46827520
      }
     },
     "aaf1b7d88d244e7a9bd13a9bb97e911c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cd667c5c9b124707a79155a90726fadf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de6fe70b193d420098037f10d984bf80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
