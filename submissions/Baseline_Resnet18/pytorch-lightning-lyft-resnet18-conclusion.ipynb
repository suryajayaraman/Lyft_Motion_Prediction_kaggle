{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Lightning version of Resnet18 baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:09.327827Z",
     "iopub.status.busy": "2020-11-14T09:13:09.326926Z",
     "iopub.status.idle": "2020-11-14T09:13:13.237584Z",
     "shell.execute_reply": "2020-11-14T09:13:13.236165Z"
    },
    "papermill": {
     "duration": 3.948053,
     "end_time": "2020-11-14T09:13:13.237728",
     "exception": false,
     "start_time": "2020-11-14T09:13:09.289675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# common imports\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from tempfile import gettempdir\n",
    "\n",
    "# interactive plot libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import init_notebook_mode, iplot # download_plotlyjs, plot\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision.models.resnet import resnet50, resnet18, resnet34, resnet101\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from torch_lr_finder import LRFinder\n",
    "\n",
    "# l5kit imports\n",
    "import l5kit\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.172595Z",
     "iopub.status.busy": "2020-11-14T09:13:14.170150Z",
     "iopub.status.idle": "2020-11-14T09:13:14.178428Z",
     "shell.execute_reply": "2020-11-14T09:13:14.179120Z"
    },
    "papermill": {
     "duration": 0.051339,
     "end_time": "2020-11-14T09:13:14.179295",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.127956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "print(l5kit.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.263220Z",
     "iopub.status.busy": "2020-11-14T09:13:14.262530Z",
     "iopub.status.idle": "2020-11-14T09:13:14.270005Z",
     "shell.execute_reply": "2020-11-14T09:13:14.273176Z"
    },
    "papermill": {
     "duration": 0.05896,
     "end_time": "2020-11-14T09:13:14.273389",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.214429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_no_of_trainable_params(model):\n",
    "    total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    #print(total_trainable_params)\n",
    "    return total_trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.357323Z",
     "iopub.status.busy": "2020-11-14T09:13:14.356420Z",
     "iopub.status.idle": "2020-11-14T09:13:14.440934Z",
     "shell.execute_reply": "2020-11-14T09:13:14.441633Z"
    },
    "papermill": {
     "duration": 0.131663,
     "end_time": "2020-11-14T09:13:14.441846",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.310183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039684,
     "end_time": "2020-11-14T09:13:14.513227",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.473543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.595175Z",
     "iopub.status.busy": "2020-11-14T09:13:14.594272Z",
     "iopub.status.idle": "2020-11-14T09:13:14.601763Z",
     "shell.execute_reply": "2020-11-14T09:13:14.602874Z"
    },
    "papermill": {
     "duration": 0.048864,
     "end_time": "2020-11-14T09:13:14.603092",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.554228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Lyft configs ---\n",
    "cfg = {\n",
    "    'format_version': 4,\n",
    "    'data_path': \"../../lyft-motion-prediction-autonomous-vehicles/\",\n",
    "    'model_params': {\n",
    "        'model_architecture': 'resnet18',\n",
    "        'history_num_frames': 10,\n",
    "        'history_step_size': 1,\n",
    "        'history_delta_time': 0.1,\n",
    "        'future_num_frames': 50,\n",
    "        'future_step_size': 1,\n",
    "        'future_delta_time': 0.1,\n",
    "        'model_name': \"R18_10_330_180_dr_conclusion\",\n",
    "        'lr': 6.3e-6,\n",
    "        'weight_path': \"R18_10_330_180_dr_conclusion_2784k.pth\",\n",
    "        'lr_find' : True, \n",
    "        'train': True, \n",
    "        'validate': False,\n",
    "        'test': False\n",
    "    },\n",
    "\n",
    "    'raster_params': {\n",
    "        'raster_size': [330, 180],\n",
    "        'pixel_size': [0.4, 0.4],\n",
    "        'ego_center': [0.25, 0.5],\n",
    "        'map_type': 'py_semantic',\n",
    "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
    "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
    "        'dataset_meta_key': 'meta.json',\n",
    "        'filter_agents_threshold': 0.5\n",
    "    },\n",
    "\n",
    "    'train_data_loader': {\n",
    "        'key': 'scenes/train.zarr',\n",
    "        'batch_size': 16,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "    \n",
    "    'val_data_loader': {\n",
    "        'key': 'scenes/validate.zarr',\n",
    "        'batch_size': 16,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "\n",
    "    \n",
    "    'test_data_loader': {\n",
    "        'key': 'scenes/test.zarr',\n",
    "        'batch_size': 32,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "\n",
    "    'train_params': {\n",
    "        'train_start_index' : 174001,\n",
    "        'max_num_steps': 11,\n",
    "        'checkpoint_every_n_steps': 5,\n",
    "        'reduction_factor' : 0.9,\n",
    "        'step_size' : 1e5\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.673878Z",
     "iopub.status.busy": "2020-11-14T09:13:14.673067Z",
     "iopub.status.idle": "2020-11-14T09:13:14.677841Z",
     "shell.execute_reply": "2020-11-14T09:13:14.678490Z"
    },
    "papermill": {
     "duration": 0.044685,
     "end_time": "2020-11-14T09:13:14.678652",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.633967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_HISTORY_FRAMES = cfg['model_params']['history_num_frames'] + 1\n",
    "RASTER_IMG_SIZE = cfg['raster_params']['raster_size'][0]\n",
    "NUM_MODES = 3\n",
    "NUMBER_OF_FUTURE_FRAMES = cfg['model_params']['future_num_frames']\n",
    "\n",
    "### TRAIN FROM WHERE LEFT OFF, CHANGE THE STARTING INDICES VARIABLE ACCORDINGLY\n",
    "TRAIN_BATCH_SIZE = cfg['train_data_loader']['batch_size'] \n",
    "TRAIN_START_INDICES = cfg['train_params']['train_start_index']\n",
    "EXTENT_RANGE = 5.0 \n",
    "MIN_FRAMES_FUTURE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.749681Z",
     "iopub.status.busy": "2020-11-14T09:13:14.748721Z",
     "iopub.status.idle": "2020-11-14T09:13:14.751202Z",
     "shell.execute_reply": "2020-11-14T09:13:14.750487Z"
    },
    "papermill": {
     "duration": 0.041572,
     "end_time": "2020-11-14T09:13:14.751327",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.709755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXTENT_RANGE = 5.0 \n",
    "MAX_VELOCITY = 20.0\n",
    "MAX_ACCELERATION = 2.0\n",
    "MAX_YAW_RATE = np.deg2rad(45)\n",
    "dt =cfg['model_params']['history_delta_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0326,
     "end_time": "2020-11-14T09:13:14.816791",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.784191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Rasterize and initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:14.911391Z",
     "iopub.status.busy": "2020-11-14T09:13:14.909517Z",
     "iopub.status.idle": "2020-11-14T09:13:21.609157Z",
     "shell.execute_reply": "2020-11-14T09:13:21.610686Z"
    },
    "papermill": {
     "duration": 6.753796,
     "end_time": "2020-11-14T09:13:21.610923",
     "exception": false,
     "start_time": "2020-11-14T09:13:14.857127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set env variable for data\n",
    "DIR_INPUT = cfg[\"data_path\"]\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = DIR_INPUT\n",
    "dm = LocalDataManager(None)\n",
    "rasterizer = build_rasterizer(cfg, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026594,
     "end_time": "2020-11-14T09:14:10.767476",
     "exception": false,
     "start_time": "2020-11-14T09:14:10.740882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:14:10.838460Z",
     "iopub.status.busy": "2020-11-14T09:14:10.837212Z",
     "iopub.status.idle": "2020-11-14T09:14:10.847780Z",
     "shell.execute_reply": "2020-11-14T09:14:10.847083Z"
    },
    "papermill": {
     "duration": 0.052976,
     "end_time": "2020-11-14T09:14:10.847893",
     "exception": false,
     "start_time": "2020-11-14T09:14:10.794917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Function utils ---\n",
    "# Original code from https://github.com/lyft/l5kit/blob/20ab033c01610d711c3d36e1963ecec86e8b85b6/l5kit/l5kit/evaluation/metrics.py\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def pytorch_neg_multi_log_likelihood_batch(\n",
    "    gt: Tensor, pred: Tensor, confidences: Tensor, avails: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Compute a negative log-likelihood for the multi-modal scenario.\n",
    "    log-sum-exp trick is used here to avoid underflow and overflow, For more information about it see:\n",
    "    https://en.wikipedia.org/wiki/LogSumExp#log-sum-exp_trick_for_log-domain_calculations\n",
    "    https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/\n",
    "    https://leimao.github.io/blog/LogSumExp/\n",
    "    Args:\n",
    "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        pred (Tensor): array of shape (bs)x(modes)x(time)x(2D coords)\n",
    "        confidences (Tensor): array of shape (bs)x(modes) with a confidence for each mode in each sample\n",
    "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
    "    Returns:\n",
    "        Tensor: negative log-likelihood for this example, a single float number\n",
    "    \"\"\"\n",
    "    assert len(pred.shape) == 4, f\"expected 3D (MxTxC) array for pred, got {pred.shape}\"\n",
    "    batch_size, num_modes, future_len, num_coords = pred.shape\n",
    "\n",
    "    assert gt.shape == (batch_size, future_len, num_coords), f\"expected 2D (Time x Coords) array for gt, got {gt.shape}\"\n",
    "    assert confidences.shape == (batch_size, num_modes), f\"expected 1D (Modes) array for gt, got {confidences.shape}\"\n",
    "    assert torch.allclose(torch.sum(confidences, dim=1), confidences.new_ones((batch_size,))), \"confidences should sum to 1\"\n",
    "    assert avails.shape == (batch_size, future_len), f\"expected 1D (Time) array for gt, got {avails.shape}\"\n",
    "    # assert all data are valid\n",
    "    assert torch.isfinite(pred).all(), \"invalid value found in pred\"\n",
    "    assert torch.isfinite(gt).all(), \"invalid value found in gt\"\n",
    "    assert torch.isfinite(confidences).all(), \"invalid value found in confidences\"\n",
    "    assert torch.isfinite(avails).all(), \"invalid value found in avails\"\n",
    "\n",
    "    # convert to (batch_size, num_modes, future_len, num_coords)\n",
    "    gt = torch.unsqueeze(gt, 1)  # add modes\n",
    "    avails = avails[:, None, :, None]  # add modes and cords\n",
    "\n",
    "    # error (batch_size, num_modes, future_len)\n",
    "    error = torch.sum(((gt - pred) * avails) ** 2, dim=-1)  # reduce coords and use availability\n",
    "\n",
    "    with np.errstate(divide=\"ignore\"):  # when confidence is 0 log goes to -inf, but we're fine with it\n",
    "        # error (batch_size, num_modes)\n",
    "        error = torch.log(confidences) - 0.5 * torch.sum(error, dim=-1)  # reduce time\n",
    "\n",
    "    # use max aggregator on modes for numerical stability\n",
    "    # error (batch_size, num_modes)\n",
    "    max_value, _ = error.max(dim=1, keepdim=True)  # error are negative at this point, so max() gives the minimum one\n",
    "    error = -torch.log(torch.sum(torch.exp(error - max_value), dim=-1, keepdim=True)) - max_value  # reduce modes\n",
    "    # print(\"error\", error)\n",
    "    return torch.mean(error)\n",
    "\n",
    "\n",
    "def pytorch_neg_multi_log_likelihood_single(\n",
    "    gt: Tensor, pred: Tensor, avails: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        pred (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
    "    Returns:\n",
    "        Tensor: negative log-likelihood for this example, a single float number\n",
    "    \"\"\"\n",
    "    # pred (bs)x(time)x(2D coords) --> (bs)x(mode=1)x(time)x(2D coords)\n",
    "    # create confidence (bs)x(mode=1)\n",
    "    batch_size, future_len, num_coords = pred.shape\n",
    "    confidences = pred.new_ones((batch_size, 1))\n",
    "    return pytorch_neg_multi_log_likelihood_batch(gt, pred.unsqueeze(1), confidences, avails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026633,
     "end_time": "2020-11-14T09:14:10.901570",
     "exception": false,
     "start_time": "2020-11-14T09:14:10.874937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:14:10.977683Z",
     "iopub.status.busy": "2020-11-14T09:14:10.976573Z",
     "iopub.status.idle": "2020-11-14T09:14:10.980055Z",
     "shell.execute_reply": "2020-11-14T09:14:10.979492Z"
    },
    "papermill": {
     "duration": 0.051905,
     "end_time": "2020-11-14T09:14:10.980163",
     "exception": false,
     "start_time": "2020-11-14T09:14:10.928258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Lit_MotionPredictor(pl.LightningModule):\n",
    "    def __init__(self, cfg: Dict, criterion, num_modes=3, lr=cfg['model_params']['lr']):\n",
    "        super().__init__()\n",
    "        \n",
    "        architecture = cfg[\"model_params\"][\"model_architecture\"]\n",
    "        # This is 512 for resnet18 and resnet34; And it is 2048 for the other resnets\n",
    "        if architecture == \"resnet50\":\n",
    "            backbone_out_features = 2048\n",
    "        else:\n",
    "            backbone_out_features = 512\n",
    "\n",
    "        num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
    "        num_in_channels = 3 + num_history_channels\n",
    "\n",
    "        # X, Y coords for the future positions (output shape: batch_sizex50x2)\n",
    "        self.future_len = cfg[\"model_params\"][\"future_num_frames\"]\n",
    "        num_targets = 2 * cfg[\"model_params\"][\"future_num_frames\"]\n",
    "        self.num_preds = num_targets * num_modes\n",
    "        self.num_modes = num_modes\n",
    "\n",
    "        ##### Layers of the model #####\n",
    "        backbone = eval(architecture)(pretrained=True)\n",
    "        self.backbone = backbone\n",
    "        self.backbone.conv1 = nn.Conv2d(\n",
    "            num_in_channels,\n",
    "            self.backbone.conv1.out_channels,\n",
    "            kernel_size=self.backbone.conv1.kernel_size,\n",
    "            stride=self.backbone.conv1.stride,\n",
    "            padding=self.backbone.conv1.padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(p =0.4)\n",
    "        \n",
    "        # You can add more layers here.\n",
    "        self.fc1 = nn.Linear(in_features=backbone_out_features, out_features=2048)\n",
    "        self.fc2 = nn.Linear(in_features=2048, out_features=512)\n",
    "        self.fc_out = nn.Linear(512, out_features= self.num_preds + self.num_modes)\n",
    "        \n",
    "        # loss function\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        # learning_rate assign\n",
    "        self.learning_rate = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "\n",
    "        x = self.backbone.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # fc layers\n",
    "        x = self.dropout(self.fc1(x))\n",
    "        x = self.dropout(self.fc2(x))\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        # pred (batch_size)x(modes)x(time)x(2D coords)\n",
    "        # confidences (batch_size)x(modes)\n",
    "        bs, _ = x.shape\n",
    "        pred, confidences = torch.split(x, self.num_preds, dim=1)\n",
    "        pred = pred.view(bs, self.num_modes, self.future_len, 2)\n",
    "        assert confidences.shape == (bs, self.num_modes)\n",
    "        confidences = torch.softmax(confidences, dim=1)\n",
    "        return pred, confidences\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #print(batch_idx)\n",
    "        inputs = batch[\"image\"]\n",
    "        target_availabilities = batch[\"target_availabilities\"]\n",
    "        targets = batch[\"target_positions\"]\n",
    "        \n",
    "        # Forward pass\n",
    "        preds, confidences = self.forward(inputs)\n",
    "        loss = self.criterion(targets, preds, confidences, target_availabilities)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lit_MotionPredictor(cfg, pytorch_neg_multi_log_likelihood_batch, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-14T09:13:21.670706Z",
     "iopub.status.busy": "2020-11-14T09:13:21.669796Z",
     "iopub.status.idle": "2020-11-14T09:14:09.446071Z",
     "shell.execute_reply": "2020-11-14T09:14:09.445115Z"
    },
    "papermill": {
     "duration": 47.805745,
     "end_time": "2020-11-14T09:14:09.446194",
     "exception": false,
     "start_time": "2020-11-14T09:13:21.640449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train dataset is  17003687\n",
      "==================================TRAIN DATA==================================\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16265    |  4039527   | 320124624  |    38735988   |      112.19     |        248.36        |        79.25         |        24.83         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "Before slicing, start indices are  [11022119 16329088 15471840  3288262  1108361 12263917 11947411 12777139\n",
      " 15959073 15744485]\n",
      "TRAIN_START_INDICES 174001\n",
      "After slicing, start indices are  [16276762 10355343   266891 15334760 12195784 11603488 11599775  9182295\n",
      "   867046 10752636]\n"
     ]
    }
   ],
   "source": [
    "# ===== INIT TRAIN DATASET============================================================\n",
    "if (cfg['model_params']['train'] == True) or (cfg['model_params']['lr_find'] == True):\n",
    "    train_cfg = cfg[\"train_data_loader\"]\n",
    "    train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
    "    train_dataset = AgentDataset(cfg, train_zarr, rasterizer, min_frame_future=MIN_FRAMES_FUTURE)\n",
    "    \n",
    "    print('Length of Train dataset is ' ,len(train_dataset))\n",
    "    print(\"==================================TRAIN DATA==================================\")\n",
    "    print(train_dataset)\n",
    "    \n",
    "    sampled_indices = np.random.choice(len(train_dataset), size = len(train_dataset), replace = False)\n",
    "    print('Before slicing, start indices are ', sampled_indices[0:10])\n",
    "    print('TRAIN_START_INDICES', TRAIN_START_INDICES)\n",
    "    \n",
    "    sampled_indices = sampled_indices[TRAIN_START_INDICES:]\n",
    "    print('After slicing, start indices are ', sampled_indices[0:10])\n",
    "    \n",
    "    Datasampler = SubsetRandomSampler(sampled_indices)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=Datasampler, batch_size=train_cfg[\"batch_size\"], \n",
    "                             num_workers=train_cfg[\"num_workers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1051856"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17003687"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173991"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(train_dataset) - len(train_dataloader) * 16) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16220    |  1622000   | 125423254  |    11733321   |      45.06      |        100.00        |        77.33         |        10.00         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "eval_base_path = cfg['data_path'] + 'scenes/validate_chopped_100'\n",
    "eval_cfg = cfg[\"val_data_loader\"]\n",
    "eval_zarr_path = str(Path(eval_base_path) / Path(dm.require(eval_cfg[\"key\"])).name)\n",
    "eval_mask_path = str(Path(eval_base_path) / \"mask.npz\")\n",
    "eval_gt_path = str(Path(eval_base_path) / \"gt.csv\")\n",
    "\n",
    "eval_zarr = ChunkedDataset(eval_zarr_path).open()\n",
    "eval_mask = np.load(eval_mask_path)[\"arr_0\"]\n",
    "# ===== INIT DATASET AND LOAD MASK\n",
    "eval_dataset = AgentDataset(cfg, eval_zarr, rasterizer, agents_mask=eval_mask)\n",
    "eval_dataloader = DataLoader(eval_dataset, shuffle=eval_cfg[\"shuffle\"], batch_size=eval_cfg[\"batch_size\"], \n",
    "                             num_workers=eval_cfg[\"num_workers\"])\n",
    "print(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, max_steps=cfg['train_params']['max_num_steps'],\n",
    "                    limit_val_batches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type    | Params\n",
      "-------------------------------------\n",
      "0 | backbone | ResNet  | 11 M  \n",
      "1 | dropout  | Dropout | 0     \n",
      "2 | fc1      | Linear  | 1 M   \n",
      "3 | fc2      | Linear  | 1 M   \n",
      "4 | fc_out   | Linear  | 155 K \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc55ba96cc94b5084da7b61e3baf483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Finding best initial lr'), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run learning rate finder\n",
    "lr_finder = trainer.tuner.lr_find(model, max_lr=1e-2, train_dataloader=train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.248074602497726e-08"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Before lr : ', model.learning_rate)\n",
    "model.learning_rate = lr_finder.suggestion()\n",
    "print('AFTER lr : ', model.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type    | Params\n",
      "-------------------------------------\n",
      "0 | backbone | ResNet  | 11 M  \n",
      "1 | dropout  | Dropout | 0     \n",
      "2 | fc1      | Linear  | 1 M   \n",
      "3 | fc2      | Linear  | 1 M   \n",
      "4 | fc_out   | Linear  | 155 K \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4edcf7791c1b4863af2d02f3f6f81ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader=train_dataloader, val_dataloaders=eval_dataloader, limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint('example.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyftMultiModel(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg: Dict, num_modes=3):\n",
    "        super().__init__()\n",
    "\n",
    "        architecture = cfg[\"model_params\"][\"model_architecture\"]\n",
    "        backbone = eval(architecture)(pretrained=True)\n",
    "        self.backbone = backbone\n",
    "\n",
    "        num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
    "        num_in_channels = 3 + num_history_channels\n",
    "\n",
    "        self.backbone.conv1 = nn.Conv2d(\n",
    "            num_in_channels,\n",
    "            self.backbone.conv1.out_channels,\n",
    "            kernel_size=self.backbone.conv1.kernel_size,\n",
    "            stride=self.backbone.conv1.stride,\n",
    "            padding=self.backbone.conv1.padding,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        # This is 512 for resnet18 and resnet34;\n",
    "        # And it is 2048 for the other resnets\n",
    "        \n",
    "        if architecture == \"resnet50\":\n",
    "            backbone_out_features = 2048\n",
    "        else:\n",
    "            backbone_out_features = 512\n",
    "\n",
    "        # X, Y coords for the future positions (output shape: batch_sizex50x2)\n",
    "        self.future_len = cfg[\"model_params\"][\"future_num_frames\"]\n",
    "        num_targets = 2 * self.future_len\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(p =0.4)\n",
    "        \n",
    "        # You can add more layers here.\n",
    "        self.fc1 = nn.Linear(in_features=backbone_out_features, out_features=2048)\n",
    "        self.fc2 = nn.Linear(in_features=2048, out_features=512)\n",
    "\n",
    "        self.num_preds = num_targets * num_modes\n",
    "        self.num_modes = num_modes\n",
    "\n",
    "        self.fc_out = nn.Linear(512, out_features=self.num_preds + num_modes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "\n",
    "        x = self.backbone.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # fc layers\n",
    "        x = self.dropout(self.fc1(x))\n",
    "        x = self.dropout(self.fc2(x))\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        # pred (batch_size)x(modes)x(time)x(2D coords)\n",
    "        # confidences (batch_size)x(modes)\n",
    "        bs, _ = x.shape\n",
    "        pred, confidences = torch.split(x, self.num_preds, dim=1)\n",
    "        pred = pred.view(bs, self.num_modes, self.future_len, 2)\n",
    "        assert confidences.shape == (bs, self.num_modes)\n",
    "        confidences = torch.softmax(confidences, dim=1)\n",
    "        return pred, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model = LyftMultiModel(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('R18_10_330_180_dr_conclusion_880k.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lit_MotionPredictor(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(25, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (fc_out): Linear(in_features=512, out_features=303, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['state_dict', 'optimizer'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR_finder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "papermill": {
   "duration": 23353.578731,
   "end_time": "2020-11-14T15:42:18.007035",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-14T09:13:04.428304",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0bf2e1a17494409e8fba1e5d1188d293": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7fbe0c3991b44670924d29e3f575d13f",
        "IPY_MODEL_755fefb7c3f94d6abdd9fceef6d3a19c"
       ],
       "layout": "IPY_MODEL_aaf1b7d88d244e7a9bd13a9bb97e911c"
      }
     },
     "544939fb29904a79bb35c7b0dd81a619": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "62041b37f7e8471cad2d615dbcce59aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "755fefb7c3f94d6abdd9fceef6d3a19c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_62041b37f7e8471cad2d615dbcce59aa",
       "placeholder": "",
       "style": "IPY_MODEL_544939fb29904a79bb35c7b0dd81a619",
       "value": " 44.7M/44.7M [00:24&lt;00:00, 1.88MB/s]"
      }
     },
     "7fbe0c3991b44670924d29e3f575d13f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cd667c5c9b124707a79155a90726fadf",
       "max": 46827520,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_de6fe70b193d420098037f10d984bf80",
       "value": 46827520
      }
     },
     "aaf1b7d88d244e7a9bd13a9bb97e911c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cd667c5c9b124707a79155a90726fadf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de6fe70b193d420098037f10d984bf80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
