{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\n\n#l5kit imports  \nfrom l5kit.data import ChunkedDataset, LocalDataManager\nfrom l5kit.dataset import EgoDataset, AgentDataset\nfrom l5kit.rasterization import build_rasterizer\nfrom l5kit.configs import load_config_data\nfrom l5kit.visualization import draw_trajectory, TARGET_POINTS_COLOR\nfrom l5kit.geometry import transform_points\nfrom l5kit.data import PERCEPTION_LABELS\nimport os\n\nimport torch\nimport pandas as pd","execution_count":36,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Configuration"},{"metadata":{"trusted":true},"cell_type":"code","source":"cfg = {\n    'format_version': 4,\n    'data_path': \"../input/lyft-motion-prediction-autonomous-vehicles/\",\n    'model_params': {\n        'model_architecture': 'resnet18',\n        'history_num_frames': 10,\n        'history_step_size': 1,\n        'history_delta_time': 0.1,\n        'future_num_frames': 50,\n        'future_step_size': 1,\n        'future_delta_time': 0.1,\n    },\n\n    'raster_params': {\n        'raster_size': [224, 224],\n        'pixel_size': [0.5, 0.5],\n        'ego_center': [0.25, 0.5],\n        'map_type': 'py_semantic',\n        'satellite_map_key': 'aerial_map/aerial_map.png',\n        'semantic_map_key': 'semantic_map/semantic_map.pb',\n        'dataset_meta_key': 'meta.json',\n        'filter_agents_threshold': 0.5\n    },\n\n    'sample_data_loader': {\n        'key': 'scenes/sample.zarr',\n        'batch_size': 16,\n        'shuffle': False,\n        'num_workers': 4\n    },\n    'train_data_loader': {\n        'key': 'scenes/train.zarr',\n        'batch_size': 16,\n        'shuffle': True,\n        'num_workers': 4\n    },\n    \n    'val_data_loader': {\n        'key': 'scenes/validate.zarr',\n        'batch_size': 16,\n        'shuffle': False,\n        'num_workers': 4\n    },\n    \n    'test_data_loader': {\n        'key': 'scenes/test.zarr',\n        'batch_size': 32,\n        'shuffle': False,\n        'num_workers': 4\n    },\n\n    'train_params': {\n        'max_num_steps': 12000,\n        'checkpoint_every_n_steps': 500,\n    }\n}","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading CUDA device"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f'device {device}')","execution_count":3,"outputs":[{"output_type":"stream","text":"device cuda:0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Loading Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"DIR_INPUT = cfg[\"data_path\"]\nos.environ[\"L5KIT_DATA_FOLDER\"] = DIR_INPUT\ndm = LocalDataManager(None)\nrasterizer = build_rasterizer(cfg, dm)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nThe agents['label_probabilities'] cannot be loaded entirely into kaggle memory\nHence dividing the dataset into batches and summing up at the end\n\nUsing GPU to run argmax improves runtime massively\n\"\"\"\n\ndef count_Agentlabels_zarr(data_loader_key):\n    dataset_path = dm.require(cfg[data_loader_key][\"key\"])\n    zarr_dataset = ChunkedDataset(dataset_path).open()\n    \n    # get agents from dataset\n    agents = zarr_dataset.agents\n    no_batches = 8\n    batch_len = round(len(agents) / no_batches )\n    total_count = []\n\n    for i in range(no_batches):\n        probabilities = torch.from_numpy(agents[i * batch_len : (i+1) * batch_len][\"label_probabilities\"]).to(device)\n        labels_indexes = torch.argmax(probabilities, dim=1)\n\n        counts = []\n        for idx_label, label in enumerate(PERCEPTION_LABELS):\n            counts.append(torch.sum(labels_indexes == idx_label))\n        counts = [x.cpu().numpy().item() for x in counts]\n        print(f'{i} batch result = {counts}')\n        total_count.append(counts)\n        del(probabilities)\n\n    agent_count =  np.sum(total_count, axis = 0).tolist()\n    print(f'Agents distribution for {data_loader_key} is ', agent_count)","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n\"\"\" Uncomment following lines to run the code \"\"\"\n#train_counts = count_Agentlabels_zarr(\"train_data_loader\")\n#val_counts = count_Agentlabels_zarr(\"val_data_loader\")\n#test_counts = count_Agentlabels_zarr(\"test_data_loader\")","execution_count":11,"outputs":[{"output_type":"stream","text":"CPU times: user 3 µs, sys: 1 µs, total: 4 µs\nWall time: 8.34 µs\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Results for Agent distribution in differnt datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_counts = [0, 214185074, 0, 96737892, 0, 0, 0, 0, 0, 0, 0, 0, 1667331, 0, 7534327, 0, 0]\nval_counts   = [0, 209417891, 0, 94918785, 0, 0, 0, 0, 0, 0, 0, 0, 1574639, 0, 6706572, 0, 0]\ntest_counts  = [0, 58143776, 0, 27888998, 0, 0, 0, 0, 0, 0, 0, 0, 486857, 0, 2075290, 0, 0]","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\"LABELS\" : PERCEPTION_LABELS, \n                   \"train_counts\" : train_counts, \n                   \"val_counts\" : val_counts,\n                   \"test_counts\" : test_counts\n                  })\n\ndf = df.set_index('LABELS')\n\n# selecting only necessary rows\ndf = df[(df.T != 0).any()]\ndf = df.drop('PERCEPTION_LABEL_UNKNOWN')","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"                             train_counts  val_counts  test_counts\nLABELS                                                            \nPERCEPTION_LABEL_CAR             96737892    94918785     27888998\nPERCEPTION_LABEL_CYCLIST          1667331     1574639       486857\nPERCEPTION_LABEL_PEDESTRIAN       7534327     6706572      2075290","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train_counts</th>\n      <th>val_counts</th>\n      <th>test_counts</th>\n    </tr>\n    <tr>\n      <th>LABELS</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>PERCEPTION_LABEL_CAR</th>\n      <td>96737892</td>\n      <td>94918785</td>\n      <td>27888998</td>\n    </tr>\n    <tr>\n      <th>PERCEPTION_LABEL_CYCLIST</th>\n      <td>1667331</td>\n      <td>1574639</td>\n      <td>486857</td>\n    </tr>\n    <tr>\n      <th>PERCEPTION_LABEL_PEDESTRIAN</th>\n      <td>7534327</td>\n      <td>6706572</td>\n      <td>2075290</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalising to percentages\nfor dataset in ['train_counts', 'val_counts', 'test_counts']:\n    df[dataset] = df[dataset] / df[dataset].sum()","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"                             train_counts  val_counts  test_counts\nLABELS                                                            \nPERCEPTION_LABEL_CAR             0.913142    0.919756     0.915860\nPERCEPTION_LABEL_CYCLIST         0.015739    0.015258     0.015988\nPERCEPTION_LABEL_PEDESTRIAN      0.071119    0.064986     0.068151","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train_counts</th>\n      <th>val_counts</th>\n      <th>test_counts</th>\n    </tr>\n    <tr>\n      <th>LABELS</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>PERCEPTION_LABEL_CAR</th>\n      <td>0.913142</td>\n      <td>0.919756</td>\n      <td>0.915860</td>\n    </tr>\n    <tr>\n      <th>PERCEPTION_LABEL_CYCLIST</th>\n      <td>0.015739</td>\n      <td>0.015258</td>\n      <td>0.015988</td>\n    </tr>\n    <tr>\n      <th>PERCEPTION_LABEL_PEDESTRIAN</th>\n      <td>0.071119</td>\n      <td>0.064986</td>\n      <td>0.068151</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n\n> ### 1. Distribution of different agents is equal for all the three datasets, which is very crucial for consistent results across training, validation and test sets. \n  \n> ### 2. Percentages of Pedestrian is around 7%, so increasing the pixel resolution might have will most likely have impact in max 7% increase (decisive for top kagglers, less for entry-level people). So, decision on pixel resolution can be decided based on tradeoff between resource and performance objective\n\n\n"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}